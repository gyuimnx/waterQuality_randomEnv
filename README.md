# 수질 안전 및 자원 최적화를 위한 강화학습(Q-Learning) 시뮬레이션

본 프로젝트는 수영장 및 상수도 소독 공정에서 발생하는 **'과잉 소독(Over-dosing)' 문제**를 해결하고, **이용객의 건강 보호(피부/안구 자극 방지)**와 **운영 비용 절감**을 동시에 달성하기 위한 AI 에이전트 개발 프로젝트입니다.

## 1. 연구 배경 및 목적
기존의 시간 기반 고정 투입 방식(**Fixed Policy**)은 오염 부하 변동에 유연하게 대처하지 못해, 안전 마진을 확보하려는 목적으로 약품을 과다 투입하는 경향이 있습니다. 
- **문제점:** 잔류염소 농도가 빈번하게 **법적 상한선(2.0mg/L)을 초과**하여, 이용객에게 **아토피 악화, 건조증, 눈병** 등 건강상의 위해를 가할 위험이 큼.
- **해결책:** 강화학습(Q-Learning)을 도입하여 수질을 인체에 무해한 **'안전 구간(Safe Zone, 0.7~1.2mg/L)'** 내에서 정밀 제어함.

## 2. 핵심 기술적 특징

### 2.1 안전 중심 보상 설계 (Safety-Aware Reward Shaping)
단순히 비용을 아끼는 것이 아니라, **'사람에게 안전한 물'**을 만드는 것을 최우선으로 학습합니다.
- **과잉 투입 패널티 (Health Risk Penalty):** 잔류염소가 2.0mg/L를 초과할 경우, 피부 손상 위험을 반영하여 **지수함수적인 강력한 벌점**을 부여합니다.
- **정밀 제어 보상:** 가장 이상적인 농도인 **0.7~1.2mg/L** 구간을 유지할 때만 높은 점수를 주어, 에이전트가 '칼날 같은 균형'을 유지하도록 유도합니다.

### 2.2 현실적인 시뮬레이션 환경 (Realistic Environment)
- **State Definition:** 잔류염소(Residual CI), 탁도(Turbidity), pH, 남은 자원량, 현재 시간(Step).
- **Environment Dynamics:** 실제 수질 거동과 유사하게 약품 투입 시 즉각적인 상승 반응과 시간 경과에 따른 자연 소멸(Decay), 돌발 오염(Shock Load) 등을 구현했습니다.

### 2.3 학습 안정화 (Stabilization)
- **Quantized State Space:** 연속적인 수질 데이터를 구간별로 나누어(Discretization) Q-Table의 학습 효율을 높였습니다.
- **Epsilon Decay:** 학습 후반부에는 탐험(Exploration)을 최소화하여, 검증된 최적 정책(Optimal Policy)대로만 행동하도록 노이즈를 제거했습니다.

## 3. 시뮬레이션 결과 (Performance Analysis)

본 시뮬레이션은 Q-Learning 에이전트와 기존 Fixed Policy(고정 주기 투입)를 3,000 에피소드 동안 비교 실험하였습니다.

| 비교 항목 | Fixed Policy (기존) | Q-Learning (제안) | 비고 |
| :--- | :--- | :--- | :--- |
| **수질 안전성** | **위험 (Frequently > 2.0mg/L)** | **매우 안전 (0.7 ~ 1.2mg/L 유지)** | **피부 자극 위험 원천 차단** |
| **제어 방식** | 과잉 투입 (Over-shooting) | 정밀 제어 (Fine Control) | 필요한 만큼만 투입 |
| **자원 소모량** | 높음 (낭비 심함) | **최적화됨 (약 20~30% 절감)** | 경제성 확보 |

> **결과 요약:** > Fixed Policy는 수질 악화를 막기 위해 습관적으로 약품을 쏟아부어 **피부 트러블 유발 농도**까지 치솟는 반면, 
> Q-Learning은 수질이 나빠지기 직전에 필요한 만큼만 투입하여 **법적/건강학적 안전 기준을 완벽하게 준수**했습니다.

## 4. 실행 방법 및 결과물

### 4.1 실행 커맨드
```bash
python train.py