# 수질 관리 및 자원 최적화 강화학습 시뮬레이션

이 프로젝트는 상수도 및 수영장 소독 공정에서 **법적 수질 가이드라인 준수**와 **소독제(자원) 소모 최소화**라는 두 가지 목표를 동시에 달성하기 위한 Q-Learning 기반의 AI 에이전트 개발 프로젝트입니다.

## 1. 프로젝트 개요
수질 관리 시스템은 외부 오염원 유입에 따라 잔류염소, 탁도, pH가 실시간으로 변하는 복잡한 환경입니다. 본 프로젝트는 사람이 설정한 고정된 규칙(Fixed Policy)보다 AI가 환경 변화를 실시간으로 인지하여 투입량을 결정하는 것이 얼마나 더 효율적인지 증명합니다.

## 2. 핵심 기술적 특징

### 2.1 지능형 리워드 설계 (Reward Shaping)
단순히 수질 기준을 넘기는 것을 넘어, 에이전트가 '안전'하고 '효율적'인 운전을 하도록 리워드 함수를 정교화했습니다:
- **수질 안전 마진(Safety Margin) 확보**: 잔류염소 수치가 법적 하한선(0.4)에 근접하지 않도록 **이상적 범위(0.7~1.2mg/L)**를 설정하고, 해당 구간 유지 시 차등화된 보상(`+0.7`)을 부여합니다.
- **다목적 최적화**: 자원 소모 패널티와 수질 유지 보상의 균형을 맞춰, 자원을 아끼면서도 수질 사고를 내지 않는 최적점을 학습합니다.

### 2.2 상태 공간 세분화 (State Representation)
에이전트가 상황을 더 명확히 구분할 수 있도록 상태 양자화(Quantization)를 개선했습니다:
- **자원 해상도 향상**: 남은 염소량 상태를 20kg 단위로 나누어 **총 10단계**로 세분화함으로써, 미세한 자원 소모량 변화가 Q-Table에 반영되도록 설계했습니다.
- **시간대별 인지**: 시간 흐름에 따른 오염도 변화를 학습하기 위해 아침/오후/저녁 상태를 포함합니다.

### 2.3 학습 안정화 전략
- **동적 탐험율(Epsilon) 제어**: 학습 후반부(80% 이후)에는 무작위 행동 확률을 `0.01`로 낮춰, 에이전트가 배운 최적의 정책에만 집중하게 함으로써 결과 그래프의 노이즈를 제거했습니다.

## 3. 주요 성과 (결과 분석)

| 지표 | Fixed Policy (기존) | Q-Learning (AI) | 개선 효과 |
| :--- | :--- | :--- | :--- |
| **자원 소모량** | 약 185kg | **약 140kg** | **약 25% 절감** |
| **수질 안정성** | 기준선 근처 주행 | **이상적 범위 내 유지** | **안전 마진 확보** |

- **자원 효율성**: 고정 정책 대비 약 25%의 자원을 덜 사용하면서도 동일하거나 더 높은 수준의 전체 리워드를 달성했습니다.
- **안정적 제어**: 수질 시뮬레이션 결과 잔류염소 수치가 위험 영역(0.4 미만)으로 떨어지지 않고 목표 구간(0.7~1.2) 내에서 매우 안정적으로 관리됨을 확인했습니다.

## 4. 실행 방법

### 4.1 환경 설정
- Python 3.x
- 라이브러리: `numpy`, `matplotlib`

### 4.2 실행
```bash
python train.py